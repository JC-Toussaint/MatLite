# MatLite

Une biblioth√®que Python offrant une interface MATLAB-like pour les op√©rations matricielles avec support natif des matrices denses et creuses, optimis√©e avec un syst√®me Copy-on-Write (COW) pour une gestion m√©moire efficace.

## Auteur

**Jean-Christophe Toussaint**  
Grenoble-INP Phelma

## Description

MatLite fournit une classe `Matrix` qui encapsule les matrices NumPy et SciPy.sparse, offrant une syntaxe famili√®re aux utilisateurs de MATLAB tout en b√©n√©ficiant de la performance des biblioth√®ques Python scientifiques et d'un syst√®me de Copy-on-Write pour une gestion m√©moire optimis√©e.

### Caract√©ristiques principales

- ‚úÖ Interface MATLAB-like intuitive
- ‚úÖ Support des matrices denses (NumPy) et creuses (SciPy.sparse)
- ‚úÖ **Syst√®me Copy-on-Write (COW)** pour optimisation m√©moire
- ‚úÖ Indexation et slicing avanc√©s compatible MATLAB
- ‚úÖ Op√©rations matricielles optimis√©es
- ‚úÖ Fonctions math√©matiques √©l√©mentaires compl√®tes
- ‚úÖ G√©n√©rateurs de matrices (zeros, ones, eye, rand, randn)
- ‚úÖ R√©solution de syst√®mes lin√©aires avec `backslash`
- ‚úÖ **Op√©rations en place avec COW automatique** (`+=`, `-=`)
- ‚úÖ **Fonctions de diagnostic COW** pour l'analyse m√©moire
- ‚úÖ **Support complet des nombres complexes**

## Installation

```bash
git clone https://github.com/JC-Toussaint/MatLite.git
cd MatLite
pip install -r requirements.txt
```

### D√©pendances

- NumPy
- SciPy
- Matplotlib (pour les exemples)

## Guide de d√©marrage rapide

```python
from MatLite import Matrix
import numpy as np

# Cr√©ation de matrices
A = Matrix([[1, 2, 3], [4, 5, 6]])        # Depuis une liste
B = Matrix(np.random.randn(3, 2))          # Depuis un array NumPy
C = Matrix.eye(3)                          # Matrice identit√© 3x3
D = Matrix.rand(5, 5, sparse=True)         # Matrice creuse al√©atoire

# Op√©rations matricielles
result = A * B                             # Produit matriciel
transposed = A.H                           # Transpos√©e conjugu√©e
norm_val = Matrix.norm(A)                  # Norme matricielle

# Indexation MATLAB-like
A[0, 1] = 10                              # Modification d'un √©l√©ment
row = A[0, :]                             # Extraction d'une ligne
col = A[:, 1]                             # Extraction d'une colonne

# R√©solution de syst√®me lin√©aire Ax = b
x = Matrix.backslash(A.H * A, A.H * B)    # Moindres carr√©s
```

## üöÄ Nouveaut√© : Copy-on-Write (COW)

MatLite int√®gre un syst√®me Copy-on-Write avanc√© qui optimise automatiquement l'utilisation m√©moire :

```python
# Cr√©ation d'une grande matrice
A = Matrix.rand(2000, 2000)  # ~32MB

# Les copies partagent les donn√©es jusqu'√† modification
B = Matrix(A)  # Instantan√©, pas de copie m√©moire
C = Matrix(A)  # Partage aussi les donn√©es avec A

# La modification d√©clenche automatiquement une copie
B[0, 0] = 999  # Seule B est copi√©e, A et C restent partag√©es

# Analyse de l'utilisation m√©moire
print("√âtat COW de A:", A.is_cow_active())
print("√âtat COW de B:", B.is_cow_active())

# Outils de diagnostic
from MatLite import memory_usage_info
memory_usage_info([A, B, C])
```

### Avantages du COW

- **√âconomie m√©moire** : Les copies partagent les donn√©es tant qu'aucune modification n'est effectu√©e
- **Performance** : Copie instantan√©e des grandes matrices
- **Transparence** : Fonctionne automatiquement, aucune modification de code n√©cessaire
- **S√©curit√©** : Garantit l'isolation des donn√©es lors des modifications

## Documentation d√©taill√©e

### Cr√©ation de matrices

```python
# Diff√©rentes fa√ßons de cr√©er des matrices
A = Matrix([[1, 2], [3, 4]])              # Liste de listes ‚Üí matrice 2x2
v = Matrix([1, 2, 3])                     # Liste ‚Üí vecteur ligne 1x3
B = Matrix(np.array([[1], [2], [3]]))     # Array NumPy ‚Üí vecteur colonne 3x1

# G√©n√©rateurs de matrices
zeros = Matrix.zeros(3, 4)                # Matrice 3x4 de z√©ros
ones = Matrix.ones(2, 2)                  # Matrice 2x2 de uns  
eye = Matrix.eye(5, k=1)                  # Matrice 5x5, uns sur sur-diagonale
rand = Matrix.rand(3, 3)                  # Matrice 3x3 al√©atoire [0,1]
randn = Matrix.randn(2, 4)                # Matrice 2x4 gaussienne N(0,1)

# Matrices creuses
sparse_eye = Matrix.eye(1000, sparse=True)        # Identit√© creuse 1000x1000
sparse_rand = Matrix.rand(100, 100, sparse=True, density=0.05)  # 5% de remplissage

# Matrices complexes
complex_rand = Matrix.rand(3, 3, dtype=complex)   # Matrice complexe al√©atoire
complex_randn = Matrix.randn(3, 3, dtype=complex) # Matrice complexe gaussienne
```

### Indexation et slicing avanc√©s

```python
A = Matrix.rand(5, 5)

# Acc√®s aux √©l√©ments
element = A[2, 3]                         # √âl√©ment (2,3)
A[1, 1] = 42                             # Modification (d√©clenche COW si n√©cessaire)

# Slicing avec COW optimis√©
row = A[2, :]                            # Ligne 2 compl√®te (vue COW si possible)
col = A[:, 1]                            # Colonne 1 compl√®te (vue COW si possible)
submatrix = A[1:4, 0:3]                  # Sous-matrice 3x3 (vue COW si possible)

# Indexation avanc√©e
selected = A[[0, 2, 4], [1, 3]]          # √âl√©ments sp√©cifiques
A[:, 0] = [1, 2, 3, 4, 5]               # Affectation de colonne (COW automatique)

# Conversion intelligente des formats MATLAB
A[:, 0] = [[1], [2], [3], [4], [5]]     # Accepte les formats colonne MATLAB
A[0, :] = [[1, 2, 3, 4, 5]]             # Accepte les formats ligne MATLAB
```

### Op√©rations matricielles

```python
A = Matrix.randn(3, 3)
B = Matrix.randn(3, 3)
v = Matrix.randn(3, 1)

# Op√©rations de base
C = A + B                                # Addition
C = A - B                                # Soustraction  
C = A * B                                # Produit matriciel
C = A * 2.5                              # Produit par scalaire
C = A / 2.0                              # Division par scalaire

# Op√©rations en place avec COW
A += B                                   # Addition en place (COW automatique)
A -= 2.5                                 # Soustraction en place (COW automatique)

# Op√©rations avanc√©es
At = A.H                                 # Transpos√©e conjugu√©e
abs_A = abs(A)                           # Valeur absolue (surcharge de abs())
neg_A = -A                               # N√©gation unaire
norm_2 = Matrix.norm(A)                  # Norme 2
norm_inf = Matrix.norm(A, np.inf)        # Norme infinie
trace_val = A.trace()                    # Trace
det_val = A.det()                        # D√©terminant
rank_val = A.rank                        # Rang (propri√©t√©)
```

### Fonctions math√©matiques compl√®tes

```python
A = Matrix.rand(3, 3) * 2 - 1  # Valeurs dans [-1, 1]

# Fonctions trigonom√©triques
sin_A = A.sin() ou sin_A = Matrix.sin(A)
cos_A = A.cos()  
tan_A = A.tan()

# Fonctions trigonom√©triques inverses
asin_A = A.asin() ou asin_A = Matrix.asin(A)
acos_A = A.acos()
atan_A = A.atan()

# Fonction atan2 (√† deux arguments)
angle = Matrix.atan2(A[:, 0], A[:, 1])   # Angle en coordonn√©es polaires

# Autres fonctions
abs_A = A.abs()  ou abs_A = Matrix.abs(A) # Valeur absolue
exp_A = A.exp()                           # Exponentielle

# Matrices complexes
A_complex = Matrix.randn(3, 3, dtype=complex)
real_part = A_complex.real               # Partie r√©elle
imag_part = A_complex.imag               # Partie imaginaire
```

### Statistiques et r√©ductions MATLAB-like

```python
A = Matrix.randn(4, 5)

# R√©ductions par d√©faut (premi√®re dimension non-singleton, comme MATLAB)
max_val = A.max()  ou max_val = Matrix.max(A) # Maximum par colonne ‚Üí vecteur ligne 1x5
min_val = A.min()                             # Minimum par colonne ‚Üí vecteur ligne 1x5  
sum_val = A.sum()                             # Somme par colonne ‚Üí vecteur ligne 1x5

# R√©ductions avec dimension sp√©cifi√©e
max_rows = A.max(dim=1)                  # Maximum par ligne ‚Üí vecteur colonne 4x1
sum_cols = A.sum(dim=0)                  # Somme par colonne (explicite)

# Pour un vecteur
v = Matrix.randn(5, 1)
max_scalar = v.max()                     # Retourne un scalaire

# Support des matrices creuses
sparse_A = Matrix.rand(1000, 1000, sparse=True, density=0.01)
sparse_sum = sparse_A.sum()              # Calcul efficace pour matrices creuses
```

### Matrices diagonales et diag()

```python
# Cr√©ation de matrice diagonale depuis un vecteur
v = Matrix([1, 2, 3, 4])
D = Matrix.diag(v)                       # Matrice 4x4 avec v sur la diagonale
D_up = Matrix.diag(v, k=1)              # v sur la sur-diagonale

# Extraction de diagonale depuis une matrice
A = Matrix.randn(5, 5)
main_diag = Matrix.diag(A)               # Diagonale principale ‚Üí vecteur colonne
upper_diag = Matrix.diag(A, k=1)         # Sur-diagonale ‚Üí vecteur colonne
lower_diag = Matrix.diag(A, k=-1)        # Sous-diagonale ‚Üí vecteur colonne
```

### Valeurs et vecteurs propres

```python
A = Matrix.randn(5, 5)
A = A + A.H  # Rendre la matrice hermitienne

# Toutes les valeurs propres (matrices denses)
eigenvals, eigenvecs = A.eig()

# Quelques valeurs propres (matrices denses ou creuses)
vals, vecs = A.eig(n=3, option='lm')     # 3 plus grandes en module
vals, vecs = A.eig(n=2, option='sm')     # 2 plus petites en module

# Pour matrices creuses (optimis√© automatiquement)
A_sparse = Matrix.rand(1000, 1000, sparse=True, density=0.01)
A_sparse = A_sparse + A_sparse.H
sparse_vals, sparse_vecs = A_sparse.eig(n=10, option='lm')
```

### R√©solution de syst√®mes lin√©aires

```python
A = Matrix.randn(5, 5)
b = Matrix.randn(5, 1)

# R√©solution directe Ax = b
x = Matrix.backslash(A, b)               # Utilise la fonction globale
x = A.backslash(b)                       # M√©thode de la classe

# Support automatique dense/creuse
A_sparse = Matrix.rand(1000, 1000, sparse=True, density=0.01)
b_sparse = Matrix.randn(1000, 1)
x_sparse = Matrix.backslash(A_sparse, b_sparse)  # Utilise spsolve automatiquement

# Fonction backslash globale avec gestion compl√®te des formats
from MatLite import backslash
x = backslash(A, b)                      # Gestion automatique des types
```

## Matrices creuses optimis√©es

MatLite g√®re intelligemment les matrices creuses SciPy avec optimisations sp√©cifiques :

```python
# Cr√©ation efficace de matrices creuses
A = Matrix.eye(1000, sparse=True)                    # Matrice identit√© creuse
B = Matrix.rand(1000, 1000, sparse=True, density=0.01)  # Matrice al√©atoire creuse

# Les op√©rations pr√©servent la sparsit√© quand c'est b√©n√©fique
C = A + B                                           # R√©sultat creuse
D = A * B                                           # Produit creuse optimis√©
norm_val = A.norm(2)                                # Calcul SVD sparse pour norme 2

# Fonctions math√©matiques sur matrices creuses
sin_sparse = A.sin()                                # Appliqu√© aux √©l√©ments non-nuls
exp_sparse = B.exp()                                # Optimis√© pour la sparsit√©

# Statistiques pour matrices creuses
max_sparse = B.max()                                # Maximum efficace
rank_sparse = B.rank                                # Rang avec SVD sparse si n√©cessaire
```

## üîß Outils de diagnostic COW

MatLite fournit des outils pour analyser et optimiser l'utilisation m√©moire :

```python
from MatLite import memory_usage_info, demonstrate_cow

# Cr√©ation de plusieurs matrices avec partage COW
A = Matrix.rand(1000, 1000)
B = Matrix(A)  # Partage avec A
C = Matrix(A)  # Partage avec A
D = A[100:200, 100:200]  # Vue sur sous-r√©gion

# Analyse d√©taill√©e de l'utilisation m√©moire
memory_usage_info([A, B, C, D])

# √âtat COW individuel
print("√âtat COW de A:", A.is_cow_active())
# Retourne: {'is_view': False, 'has_children': True, 'is_modified': False, 
#           'children_count': 3, 'has_parent': False}

# D√©monstration compl√®te du COW
demonstrate_cow()  # Exemple interactif des avantages COW
```

## Exemples d'utilisation

### Algorithme du Gradient Conjugu√© avec COW

```python
def cg(A, b, tol=1.0e-6):
    """Gradient conjugu√© optimis√© avec COW"""
    sz = A.shape
    assert sz[0] == sz[1]
    
    x = Matrix.rand(sz[0], 1, random_state=42)
    r = b - A * x  # COW √©vite les copies inutiles
    p = Matrix(r)  # Partage initial avec r
    
    k = 0
    while Matrix.norm(r) > tol * Matrix.norm(b):
        k += 1
        a = (p.H * r) / (p.H * A * p)
        x += a * p  # Op√©ration en place avec COW
        r = b - A * x
        beta = -(p.H * A * r) / (p.H * A * p)
        p = r + beta * p
    
    return x, k

# Test avec matrice d√©finie positive
N = 100
A = Matrix.rand(N, N, random_state=42)
A = A + A.H + N * Matrix.eye(N)  # Rend A d√©finie positive
b = Matrix.rand(N, 1, random_state=42)

x, iterations = cg(A, b)
print(f'Iterations: {iterations}, R√©sidu: {Matrix.norm(b - A * x, np.inf)}')
```

### Analyse spectrale avec matrices complexes

```python
# Matrice hermitienne complexe
A = Matrix.randn(4, 4, dtype=complex)
A = A + A.H  # Rendre hermitienne

# Calcul des valeurs propres (r√©elles pour matrice hermitienne)
eigenvals, eigenvecs = A.eig()
print("Valeurs propres:", eigenvals)
print("Parties r√©elles des vecteurs propres:")
print(eigenvecs.real)
print("Parties imaginaires des vecteurs propres:")
print(eigenvecs.imag)

# V√©rification de l'orthogonalit√©
Q = eigenvecs
QHQ = Q.H * Q
print("V√©rification orthogonalit√© (doit √™tre ‚âà I):")
print(abs(QHQ - Matrix.eye(4, dtype=complex)))
```

### G√©n√©ration et analyse de donn√©es avec optimisation m√©moire

```python
# G√©n√©ration de grandes matrices avec COW
data = Matrix.randn(10000, 50)  # 100k points en 50D

# Cr√©ation de vues avec COW pour analyse
train_data = data[:8000, :]     # Vue COW sur donn√©es d'entra√Ænement
test_data = data[8000:, :]      # Vue COW sur donn√©es de test

# Statistiques (pas de copie m√©moire gr√¢ce au COW)
train_means = train_data.sum(dim=0) / 8000    # Moyennes par colonne
train_stds = ((train_data - train_means).abs().sum(dim=0)) / 8000

# Normalisation (d√©clenche COW seulement si n√©cessaire)
normalized_train = (train_data - train_means) / train_stds
normalized_test = (test_data - train_means) / train_stds

print("Analyse m√©moire apr√®s normalisation:")
memory_usage_info([data, train_data, test_data, normalized_train, normalized_test])
```

## Compatibilit√© MATLAB √©tendue

MatLite reproduit fid√®lement le comportement de MATLAB avec des extensions :

| MATLAB | MatLite | Description |
|--------|---------|-------------|
| `A = [1 2; 3 4]` | `A = Matrix([[1, 2], [3, 4]])` | Cr√©ation de matrice |
| `A(2,3)` | `A[1, 2]` | Indexation (base 0 en Python) |
| `A(:,2)` | `A[:, 1]` | Extraction de colonne |
| `A \ b` | `Matrix.backslash(A, b)` | R√©solution syst√®me lin√©aire |
| `max(A)` | `A.max()` | Maximum par colonne |
| `max(A, [], 2)` | `A.max(dim=1)` | Maximum par ligne |
| `norm(A,2)` | `A.norm(2)` | Norme matricielle |
| `norm(A,'fro')` | `A.norm('fro')` | Norme de Frobenius |
| `eig(A)` | `A.eig()` | Valeurs/vecteurs propres |
| `diag(v)` | `Matrix.diag(v)` | Matrice diagonale |
| `diag(A,k)` | `Matrix.diag(A, k)` | Extraction de diagonale |
| `eye(n)` | `Matrix.eye(n)` | Matrice identit√© |
| `zeros(m,n)` | `Matrix.zeros(m, n)` | Matrice de z√©ros |
| `ones(m,n)` | `Matrix.ones(m, n)` | Matrice de uns |
| `rand(m,n)` | `Matrix.rand(m, n)` | Matrice al√©atoire |
| `randn(m,n)` | `Matrix.randn(m, n)` | Matrice gaussienne |
| `sin(A)` | `A.sin()` | Sinus √©l√©ment par √©l√©ment |
| `abs(A)` | `A.abs()` ou `abs(A)` | Valeur absolue |
| `A += B` | `A += B` | **Addition en place (nouveau)** |
| `real(A)` | `A.real` | **Partie r√©elle (nouveau)** |
| `imag(A)` | `A.imag` | **Partie imaginaire (nouveau)** |
| `atan2(Y,X)` | `Matrix.atan2(Y, X)` | **Fonction atan2 (nouveau)** |

## Performance et optimisation m√©moire

### Comparaison avec/sans COW

```python
import time

# Test de performance COW
A = Matrix.rand(2000, 2000)  # ~32MB

# Copie COW (instantan√©e)
start = time.time()
B = Matrix(A)
print(f"COW copy: {time.time() - start:.6f}s")  # ~0.000001s

# Copie forc√©e (lente)
start = time.time()
C = A.copy()
print(f"Force copy: {time.time() - start:.3f}s")  # ~0.1s

# √âconomie m√©moire avec COW
matrices = [Matrix(A) for _ in range(10)]  # 10 "copies"
memory_usage_info(matrices)  # Montre le partage m√©moire
```

### Recommandations d'utilisation

1. **Utilisez COW par d√©faut** : Les copies sont automatiquement optimis√©es
2. **Forcez la copie** si vous savez que vous allez beaucoup modifier : `A.copy()`
3. **Surveillez l'√©tat COW** avec `is_cow_active()` pour le debugging
4. **Pr√©f√©rez les matrices creuses** pour les grandes matrices peu denses
5. **Utilisez les op√©rations en place** (`+=`, `-=`) pour √©viter les allocations

## API de diagnostic avanc√©e

```python
# Analyse d√©taill√©e d'une matrice
A = Matrix.rand(100, 100)
B = Matrix(A)

print("Informations COW d√©taill√©es:")
print(f"A: {A.is_cow_active()}")
print(f"B: {B.is_cow_active()}")

# Modification et impact sur le COW
B[0, 0] = 999
print(f"Apr√®s modification de B: {B.is_cow_active()}")
print(f"Impact sur A: {A.is_cow_active()}")

# V√©rification de l'ind√©pendance des donn√©es
print(f"A[0,0] = {A[0,0]} (inchang√©)")
print(f"B[0,0] = {B[0,0]} (modifi√©)")
```

## Licence

Ce projet est sous licence MIT.

## Contribution

Les contributions sont les bienvenues ! N'h√©sitez pas √† :

1. Forker le projet
2. Cr√©er une branche pour votre fonctionnalit√© (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commiter vos changements (`git commit -am 'Ajoute une nouvelle fonctionnalit√©'`)
4. Pousser vers la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. Cr√©er une Pull Request

### Zones de contribution prioritaires

- Extension des fonctions math√©matiques
- Optimisations pour matrices tr√®s creuses
- Support de nouveaux formats de matrices
- Am√©lioration des algorithmes de diagnostic COW
- Documentation et exemples suppl√©mentaires

## Contact

Pour toute question ou suggestion :
- **Auteur :** Jean-Christophe Toussaint
- **Affiliation :** Grenoble-INP Phelma

---

*MatLite - Bringing MATLAB syntax to Python's scientific computing ecosystem with advanced memory optimization*